{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIWz5AkGW+gHEvnilM52dP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mystic-miracle/DataDiveStudyMaterial/blob/main/DataDive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhFrXwmqYSwb",
        "outputId": "caba1d58-db94-408e-a1db-3208a689ffc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.11.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow is a “Google” product.\n",
        "\n",
        "TensorFlow is an open-source software library for dataflow and differentiable programming across a range of tasks. It is primarily used for machine learning applications, particularly in the areas of deep learning and neural networks.\n",
        "\n",
        "\n",
        "It includes a feature of that defines, optimizes and calculates mathematical expressions easily with the help of multi-dimensional arrays called tensors.\n",
        "\n",
        "It includes a programming support of deep neural networks and machine learning techniques.\n",
        "\n",
        "It includes a high scalable feature of computation with various data sets.\n",
        "\n",
        "TensorFlow uses GPU computing, automating management. It also includes a unique feature of optimization of same memory and the data used."
      ],
      "metadata": {
        "id": "MUIIv4_KZB-D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor Data Structure**\n",
        "Tensors are used as the basic data structures in TensorFlow language. Tensors represent the connecting edges in any flow diagram called the Data Flow Graph. Tensors are defined as multidimensional array or list.\n",
        "\n",
        "Tensors are identified by the following three parameters −\n",
        "\n",
        "\n",
        "**Rank**\n",
        "\n",
        "Unit of dimensionality described within tensor is called rank. It identifies the number of dimensions of the tensor. A rank of a tensor can be described as the order or n-dimensions of a tensor defined.\n",
        "\n",
        "**Shape**\n",
        "\n",
        "The number of rows and columns together define the shape of Tensor.\n",
        "\n",
        "**Type** \n",
        "\n",
        "Type describes the data type assigned to Tensor’s elements.\n",
        "\n",
        " \n"
      ],
      "metadata": {
        "id": "HWRRnFpuafaK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In TensorFlow, a tensor is a fundamental data structure that represents a multi-dimensional array or a list of values that can be processed by operations defined in the TensorFlow library. A tensor can be thought of as a generalization of a matrix, with an arbitrary number of dimensions."
      ],
      "metadata": {
        "id": "y-krmi7PbZPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate some data with a linear relationship\n",
        "np.random.seed(0)\n",
        "X = np.linspace(0, 10, 100)\n",
        "y = 2 * X + 1 + np.random.randn(100)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=1, input_shape=[1])\n",
        "])\n",
        "\n",
        "# Compile the model with a mean squared error loss and stochastic gradient descent optimizer\n",
        "model.compile(loss='mse', optimizer=tf.keras.optimizers.SGD(0.01))\n",
        "\n",
        "# Train the model for 100 epochs\n",
        "history = model.fit(X, y, epochs=100)\n",
        "\n",
        "# Plot the results\n",
        "plt.scatter(X, y)\n",
        "plt.plot(X, model.predict(X), color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Oi49QMl60hI3",
        "outputId": "74597c67-0e47-41e4-b01f-632fa40328d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 48.4373\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2455\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.4348\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2492\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2179\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.3378\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2833\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1805\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2060\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.2140\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1540\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1614\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2651\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1365\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1424\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2921\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1359\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1214\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2036\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2343\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2356\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1139\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1337\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1202\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1202\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1651\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1274\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1015\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1443\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1066\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0720\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0750\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1205\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0634\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0949\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0681\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1809\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0778\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0627\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0678\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0652\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1182\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0901\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0475\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0854\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0611\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0872\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0985\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0801\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0441\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0559\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0391\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0345\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0575\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0576\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0652\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0481\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0996\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0411\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1157\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0826\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0479\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0784\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1332\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0634\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0678\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0625\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0900\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0518\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1541\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0723\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0322\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0398\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0409\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0655\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0312\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0588\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0374\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1184\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0597\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0567\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0519\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0443\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0295\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0254\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1543\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0467\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0192\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0674\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0287\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0358\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0479\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0509\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0429\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0289\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0350\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0332\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0340\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0120\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0382\n",
            "4/4 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DIcvWO281ce7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# create a tensor with a single value\n",
        "scalar_tensor = tf.constant(42)\n",
        "print(scalar_tensor)  # output: tf.Tensor(42, shape=(), dtype=int32)\n",
        "\n",
        "# create a tensor with a 1D shape (i.e., a vector)\n",
        "vector_tensor = tf.constant([1, 2, 3, 4, 5])\n",
        "print(vector_tensor)  # output: tf.Tensor([1 2 3 4 5], shape=(5,), dtype=int32)\n",
        "\n",
        "# create a tensor with a 2D shape (i.e., a matrix)\n",
        "matrix_tensor = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "print(matrix_tensor)  # output: tf.Tensor(\n",
        "                      #           [[1 2 3]\n",
        "                      #            [4 5 6]\n",
        "                      #            [7 8 9]], shape=(3, 3), dtype=int32)\n",
        "print(tf.rank(matrix_tensor))\n",
        "# perform arithmetic operations on tensors\n",
        "x = tf.constant(10)\n",
        "y = tf.constant(20)\n",
        "addition = tf.add(x, y)\n",
        "subtraction = tf.subtract(x, y)\n",
        "multiplication = tf.multiply(x, y)\n",
        "division = tf.divide(y, x)\n",
        "print(addition)      # output: tf.Tensor(30, shape=(), dtype=int32)\n",
        "print(subtraction)   # output: tf.Tensor(-10, shape=(), dtype=int32)\n",
        "print(multiplication)  # output: tf.Tensor(200, shape=(), dtype=int32)\n",
        "print(division)      # output: tf.Tensor(2.0, shape=(), dtype=float64)\n",
        "\n",
        "# perform matrix multiplication on tensors\n",
        "a = tf.constant([[1, 2], [3, 4]])\n",
        "b = tf.constant([[5, 6], [7, 8]])\n",
        "matrix_product = tf.matmul(a, b)\n",
        "print(matrix_product)  # output: tf.Tensor(\n",
        "                       #           [[19 22]\n",
        "                       #            [43 50]], shape=(2, 2), dtype=int32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr-YaiCSbcwT",
        "outputId": "c722b94e-4b5b-48b8-9f26-feb12f3a6957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(42, shape=(), dtype=int32)\n",
            "tf.Tensor([1 2 3 4 5], shape=(5,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]], shape=(3, 3), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(30, shape=(), dtype=int32)\n",
            "tf.Tensor(-10, shape=(), dtype=int32)\n",
            "tf.Tensor(200, shape=(), dtype=int32)\n",
            "tf.Tensor(2.0, shape=(), dtype=float64)\n",
            "tf.Tensor(\n",
            "[[19 22]\n",
            " [43 50]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FEatures of Tensors"
      ],
      "metadata": {
        "id": "2c9heRlicRp1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data types"
      ],
      "metadata": {
        "id": "RpVzVwDacTd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# create tensors with different data types\n",
        "int_tensor = tf.constant(42)\n",
        "float_tensor = tf.constant(3.14)\n",
        "bool_tensor = tf.constant(True)\n",
        "\n",
        "# check the data types of the tensors\n",
        "print(int_tensor.dtype)    # output: <dtype: 'int32'>\n",
        "print(float_tensor.dtype)  # output: <dtype: 'float32'>\n",
        "print(bool_tensor.dtype)   # output: <dtype: 'bool'>\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cf607jObcVEJ",
        "outputId": "b388e971-a30c-4169-8d06-38f44549c458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<dtype: 'int32'>\n",
            "<dtype: 'float32'>\n",
            "<dtype: 'bool'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Broadcasting"
      ],
      "metadata": {
        "id": "HQBelRNJcbk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# create tensors with different shapes\n",
        "a = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
        "b = tf.constant([10, 20, 30])\n",
        "\n",
        "# perform element-wise multiplication with broadcasting\n",
        "c = tf.multiply(a, b)\n",
        "print(c)  # output: tf.Tensor(\n",
        "          #           [[10 40 90]\n",
        "          #            [40 100 180]], shape=(2, 3), dtype=int32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqEywa1ycach",
        "outputId": "52ba9f6b-6204-4907-d2ca-2d765d7f9743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 10  40  90]\n",
            " [ 40 100 180]], shape=(2, 3), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slicing and indexing"
      ],
      "metadata": {
        "id": "SUb1ScFQcoU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# create a tensor\n",
        "tensor = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "\n",
        "# slice the tensor to extract a sub-tensor\n",
        "sub_tensor = tensor[1:, :-1]\n",
        "print(sub_tensor)  # output: tf.Tensor(\n",
        "                   #           [[4 5]\n",
        "                   #            [7 8]], shape=(2, 2), dtype=int32)\n",
        "\n",
        "# index the tensor to extract a specific element\n",
        "element = tensor[2, 1]\n",
        "print(element)  # output: tf.Tensor(8, shape=(), dtype=int32)\n"
      ],
      "metadata": {
        "id": "jx4LrDzXcqKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshaping"
      ],
      "metadata": {
        "id": "vRudETdpctXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# create a tensor\n",
        "tensor = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "\n",
        "# reshape the tensor to change its dimensions\n",
        "reshaped_tensor = tf.reshape(tensor, [9])\n",
        "print(reshaped_tensor)  # output: tf.Tensor([1 2 3 4 5 6 7 8 9], shape=(9,), dtype=int32)\n"
      ],
      "metadata": {
        "id": "vRN5r2ivcsYJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb2b986a-6337-49fb-afe0-56b432e38415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1 2 3 4 5 6 7 8 9], shape=(9,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU acceleration:"
      ],
      "metadata": {
        "id": "xuoOgiBycw1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# create tensors and perform operations on them\n",
        "a = tf.constant([[1, 2], [3, 4]])\n",
        "b = tf.constant([[5, 6], [7, 8]])\n",
        "c = tf.matmul(a, b)\n",
        "\n",
        "# check if GPU acceleration is available\n",
        "if tf.test.is_gpu_available():\n",
        "    print('GPU acceleration is available!')\n",
        "else:\n",
        "    print('GPU acceleration is not available.')\n",
        "\n",
        "# run the operation on the GPU (if available)\n",
        "with tf.device('/GPU:0'):\n",
        "    c = tf.matmul(a, b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTJJ7ytKcyzd",
        "outputId": "f526edfe-6f42-43c8-8a3e-d0d7529178fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-82072084d40f>:9: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU acceleration is not available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Serialization:"
      ],
      "metadata": {
        "id": "RZtLFKwpdNe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# create a tensor and save it to disk\n",
        "tensor = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "tf.saved_model.save(tensor, 'my_tensor')\n",
        "\n",
        "# load the tensor back into memory\n",
        "loaded_tensor = tf.saved_model.load('my_tensor')\n",
        "print(loaded_tensor)  # output: <tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject object at 0x7f3b002d37d0>\n"
      ],
      "metadata": {
        "id": "1GFBwYBXdSOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "\n",
        "# load the Boston Housing Dataset\n",
        "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n",
        "\n",
        "# create a DataFrame from the data\n",
        "df = pd.DataFrame(train_data, columns=[\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\"])\n",
        "df[\"MEDV\"] = train_targets\n",
        "\n",
        "# display the first few rows of the DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "PhBjfX8qfbHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# load the dataset\n",
        "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n",
        "\n",
        "# normalize the data\n",
        "mean = train_data.mean(axis=0)\n",
        "std = train_data.std(axis=0)\n",
        "train_data = (train_data - mean) / std\n",
        "test_data = (test_data - mean) / std\n",
        "\n",
        "# define the model architecture\n",
        "model = Sequential([\n",
        "  Dense(64, activation='relu', input_shape=(train_data.shape[1],)),\n",
        "  Dropout(0.5),\n",
        "  Dense(64, activation='relu'),\n",
        "  Dropout(0.5),\n",
        "  Dense(1)\n",
        "])\n",
        "\n",
        "# compile the model with a mean squared error loss function and Adam optimizer\n",
        "model.compile(loss='mse', optimizer=Adam(lr=0.001))\n",
        "\n",
        "# train the model\n",
        "model.fit(train_data, train_targets, validation_split=0.2, epochs=100, batch_size=16)\n",
        "\n",
        "# evaluate the model on the test data\n",
        "test_loss = model.evaluate(test_data, test_targets)\n",
        "print('Test Loss:', test_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuLFAMD_fgRL",
        "outputId": "210c843e-f242-481c-e021-cb92243b1bc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "21/21 [==============================] - 1s 10ms/step - loss: 528.5274 - val_loss: 556.0770\n",
            "Epoch 2/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 445.0695 - val_loss: 462.6242\n",
            "Epoch 3/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 342.9111 - val_loss: 331.6998\n",
            "Epoch 4/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 214.5701 - val_loss: 191.3640\n",
            "Epoch 5/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 131.6638 - val_loss: 110.3148\n",
            "Epoch 6/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 108.8336 - val_loss: 78.3072\n",
            "Epoch 7/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 80.2594 - val_loss: 57.3265\n",
            "Epoch 8/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 75.3421 - val_loss: 48.8672\n",
            "Epoch 9/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 74.2653 - val_loss: 47.7453\n",
            "Epoch 10/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 64.6038 - val_loss: 41.1290\n",
            "Epoch 11/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 64.3519 - val_loss: 32.9883\n",
            "Epoch 12/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 57.8032 - val_loss: 30.0095\n",
            "Epoch 13/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 53.7756 - val_loss: 28.6792\n",
            "Epoch 14/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 58.0198 - val_loss: 27.0541\n",
            "Epoch 15/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 60.1287 - val_loss: 24.3766\n",
            "Epoch 16/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 53.8080 - val_loss: 22.8005\n",
            "Epoch 17/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 54.6461 - val_loss: 19.7591\n",
            "Epoch 18/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 49.0799 - val_loss: 22.3347\n",
            "Epoch 19/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 47.7976 - val_loss: 22.4609\n",
            "Epoch 20/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 44.8207 - val_loss: 18.9887\n",
            "Epoch 21/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 51.8359 - val_loss: 17.5394\n",
            "Epoch 22/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 45.9668 - val_loss: 20.6570\n",
            "Epoch 23/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 46.7330 - val_loss: 18.3893\n",
            "Epoch 24/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 44.3300 - val_loss: 16.8759\n",
            "Epoch 25/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 51.1885 - val_loss: 17.2606\n",
            "Epoch 26/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 44.2697 - val_loss: 17.3318\n",
            "Epoch 27/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 47.3803 - val_loss: 16.3831\n",
            "Epoch 28/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 44.2312 - val_loss: 17.9361\n",
            "Epoch 29/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 47.8872 - val_loss: 16.6795\n",
            "Epoch 30/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 44.6920 - val_loss: 16.5357\n",
            "Epoch 31/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 41.9183 - val_loss: 17.5203\n",
            "Epoch 32/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 50.4853 - val_loss: 16.4861\n",
            "Epoch 33/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 48.6235 - val_loss: 16.5129\n",
            "Epoch 34/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 45.4375 - val_loss: 15.5013\n",
            "Epoch 35/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 42.8899 - val_loss: 15.2253\n",
            "Epoch 36/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 45.9337 - val_loss: 15.8243\n",
            "Epoch 37/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 37.3131 - val_loss: 14.9515\n",
            "Epoch 38/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 44.0732 - val_loss: 16.4839\n",
            "Epoch 39/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 43.5640 - val_loss: 14.4181\n",
            "Epoch 40/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 44.8695 - val_loss: 16.3171\n",
            "Epoch 41/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 37.1011 - val_loss: 16.2933\n",
            "Epoch 42/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 38.8397 - val_loss: 14.0184\n",
            "Epoch 43/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 39.1410 - val_loss: 14.7331\n",
            "Epoch 44/100\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 45.0907 - val_loss: 14.4881\n",
            "Epoch 45/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 41.7245 - val_loss: 13.4187\n",
            "Epoch 46/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 40.9815 - val_loss: 13.9369\n",
            "Epoch 47/100\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 44.2797 - val_loss: 16.1291\n",
            "Epoch 48/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 41.2003 - val_loss: 19.0286\n",
            "Epoch 49/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 43.6756 - val_loss: 16.4110\n",
            "Epoch 50/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 38.7766 - val_loss: 14.1464\n",
            "Epoch 51/100\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 40.6342 - val_loss: 14.4112\n",
            "Epoch 52/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 40.6043 - val_loss: 12.5800\n",
            "Epoch 53/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 40.3238 - val_loss: 13.3369\n",
            "Epoch 54/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 42.2328 - val_loss: 17.6034\n",
            "Epoch 55/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 42.5889 - val_loss: 14.9283\n",
            "Epoch 56/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 34.4680 - val_loss: 13.0550\n",
            "Epoch 57/100\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 36.0437 - val_loss: 13.0794\n",
            "Epoch 58/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 40.8149 - val_loss: 13.0327\n",
            "Epoch 59/100\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 37.9941 - val_loss: 12.8431\n",
            "Epoch 60/100\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 34.9733 - val_loss: 13.7908\n",
            "Epoch 61/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 37.7360 - val_loss: 15.3969\n",
            "Epoch 62/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 34.4727 - val_loss: 11.5446\n",
            "Epoch 63/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 39.8314 - val_loss: 13.1845\n",
            "Epoch 64/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 37.2042 - val_loss: 13.5134\n",
            "Epoch 65/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 36.6074 - val_loss: 13.6938\n",
            "Epoch 66/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 42.5264 - val_loss: 13.2562\n",
            "Epoch 67/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 35.6617 - val_loss: 14.1038\n",
            "Epoch 68/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 37.6886 - val_loss: 14.8873\n",
            "Epoch 69/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 41.4439 - val_loss: 13.4710\n",
            "Epoch 70/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 42.5481 - val_loss: 17.0748\n",
            "Epoch 71/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 34.3751 - val_loss: 13.7539\n",
            "Epoch 72/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 37.3808 - val_loss: 13.1350\n",
            "Epoch 73/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 41.4255 - val_loss: 13.8624\n",
            "Epoch 74/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 38.1062 - val_loss: 15.1502\n",
            "Epoch 75/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 37.3252 - val_loss: 13.3113\n",
            "Epoch 76/100\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 33.9222 - val_loss: 14.0268\n",
            "Epoch 77/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 41.5082 - val_loss: 13.3180\n",
            "Epoch 78/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 36.9735 - val_loss: 13.8474\n",
            "Epoch 79/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 34.5986 - val_loss: 13.7127\n",
            "Epoch 80/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 45.4851 - val_loss: 18.7194\n",
            "Epoch 81/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 38.3494 - val_loss: 14.9322\n",
            "Epoch 82/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 36.4060 - val_loss: 13.9854\n",
            "Epoch 83/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 32.1149 - val_loss: 13.4335\n",
            "Epoch 84/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 36.8273 - val_loss: 13.1008\n",
            "Epoch 85/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 36.7892 - val_loss: 12.6695\n",
            "Epoch 86/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 30.3982 - val_loss: 13.2290\n",
            "Epoch 87/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 37.5520 - val_loss: 12.8048\n",
            "Epoch 88/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 39.8241 - val_loss: 13.6210\n",
            "Epoch 89/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 38.9013 - val_loss: 14.6735\n",
            "Epoch 90/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 35.4308 - val_loss: 12.4243\n",
            "Epoch 91/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 31.4872 - val_loss: 12.8949\n",
            "Epoch 92/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 34.1523 - val_loss: 12.5675\n",
            "Epoch 93/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 34.5329 - val_loss: 11.9013\n",
            "Epoch 94/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 33.8289 - val_loss: 14.1774\n",
            "Epoch 95/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 33.0503 - val_loss: 13.0521\n",
            "Epoch 96/100\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 38.9625 - val_loss: 14.0040\n",
            "Epoch 97/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 33.0564 - val_loss: 14.2327\n",
            "Epoch 98/100\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 36.8763 - val_loss: 14.9867\n",
            "Epoch 99/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 34.0302 - val_loss: 13.3393\n",
            "Epoch 100/100\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 34.0679 - val_loss: 12.7862\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 25.4461\n",
            "Test Loss: 25.446083068847656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = model.evaluate(test_data, test_targets)\n",
        "print('Test Loss:', test_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fX0eagvUgfE6",
        "outputId": "3e9dc475-026a-49fe-ce16-838f7120c729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 7ms/step - loss: 25.4461\n",
            "Test Loss: 25.446083068847656\n"
          ]
        }
      ]
    }
  ]
}